{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72e2963-a6f3-425a-9aa8-8619b9d52a8e",
   "metadata": {},
   "source": [
    "# Transitioning to autonomous driving: <br>Mixed vehicle autonomy levels on freeways\n",
    "### Notebook to analyse traffic performance and safety for scenario 0-33-33-33 compared to scenario 25-25-25-25.\n",
    "\n",
    "Jesse Poland<br>\n",
    "TU Delft<br>\n",
    "Date: 02-10-2024<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e3d51-1e7a-4202-87d8-904cb43e85bd",
   "metadata": {},
   "source": [
    "### 0. Python packages and loading data files\n",
    "\n",
    "First, Python packages are imported to provide specific functionalities within the notebook. Then, the file paths are set to retrieve stored simulation data for all experiment runs and seeds. The simulation data is loaded into Pandas DataFrames, making the data ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06354244-1613-445d-9ce4-ce5df1af7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "from IPython.display import display\n",
    "import zipfile\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1dab4d1-2072-4169-84c6-7ba48803de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation output folder\n",
    "experiment_name = 'policy_run_1'\n",
    "\n",
    "# load Java simulation data\n",
    "experiment_folder = fr'F:\\jesse_sim_results\\{experiment_name}'\n",
    "# experiment_folder = fr'..\\data\\{experiment_name}'\n",
    "\n",
    "# available files\n",
    "input_values = 'inputValues.csv'\n",
    "intermediate_output = 'intermediateOutputData.csv'\n",
    "single_output = 'singleOutputData.csv'\n",
    "sequence_output = 'sequenceOutputData.csv'\n",
    "lane_change_output = 'laneChangeOutputData.csv'\n",
    "collision_output = 'collisionOutputData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ddf67e-1b26-4587-b993-28beaff4cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get a list of all file/folder names within a folder\n",
    "def get_file_names(path):\n",
    "    return os.listdir(path)\n",
    "\n",
    "# load available seed folders\n",
    "seed_folders = get_file_names(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2120b9-245e-432a-86a5-b64a47b9c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve any data within the project folder as dataframe\n",
    "def load_scenario_dataframe(scenario, columns_of_interest, folder, file, input_file):\n",
    "    # create empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # loop through all seed folders from this experiment\n",
    "    for seed_name in get_file_names(folder):\n",
    "        \n",
    "        # get all runs within this experiment\n",
    "        run_folders = get_file_names(os.path.join(folder, seed_name))\n",
    "\n",
    "        # go through all runs\n",
    "        for run_folder in run_folders:\n",
    "            run_number = int(run_folder.split('_')[1])\n",
    "            data_folder = os.path.join(folder, seed_name, run_folder)\n",
    "\n",
    "            # initialise scenario boolean\n",
    "            row_matches_scenario = False\n",
    "\n",
    "            # open zip file (remove .csv form file name)\n",
    "            # try:\n",
    "            # check whether input file matches this scenario\n",
    "            # open input zip file\n",
    "            with zipfile.ZipFile(os.path.join(data_folder, fr'{input_file[:-4]}.zip'), 'r') as zip_ref:\n",
    "                # read input csv\n",
    "                with zip_ref.open(input_file) as input_data_file:\n",
    "                    df_input = pd.read_csv(input_data_file)\n",
    "                    row_matches_scenario = all(df_input.iloc[0][key] == value for key, value in scenario.items())\n",
    "                    \n",
    "            # get data if input values match this scenario\n",
    "            if row_matches_scenario:\n",
    "                with zipfile.ZipFile(os.path.join(data_folder, fr'{file[:-4]}.zip'), 'r') as zip_ref:\n",
    "                    # read sequence csv\n",
    "                    with zip_ref.open(file) as data_file:\n",
    "                        df_run = pd.read_csv(data_file)\n",
    "                        df_interest = df_run[columns_of_interest].copy()\n",
    "                        df_interest['run'] = run_number\n",
    "\n",
    "                        # broadcast input data to all rows in df_interest\n",
    "                        for col in df_input.columns:\n",
    "                            df_interest[col] = df_input[col].iloc[0]\n",
    "                    \n",
    "                        # add this data to the main DataFrame\n",
    "                        df = pd.concat([df, df_interest])\n",
    "            # except:\n",
    "            #     print(f'An error occured when trying to read data from: {data_folder}. This folder may contain a BadZipFile.')\n",
    "    \n",
    "    # return resulting DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to retrieve any data within the project folder as dataframe\n",
    "def load_scenario_collision_dataframe(scenario, folder):\n",
    "    # collision file\n",
    "    file = collision_output\n",
    "    input_file = input_values\n",
    "    \n",
    "    # create empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # loop through all seed folders from this experiment\n",
    "    for seed_name in get_file_names(folder):\n",
    "        \n",
    "        # get all runs within this experiment\n",
    "        run_folders = get_file_names(os.path.join(folder, seed_name))\n",
    "\n",
    "        # go through all runs\n",
    "        for run_folder in run_folders:\n",
    "            run_number = int(run_folder.split('_')[1])\n",
    "            data_folder = os.path.join(folder, seed_name, run_folder)\n",
    "\n",
    "            # initialise scenario boolean\n",
    "            row_matches_scenario = False\n",
    "\n",
    "            # open zip file (remove .csv form file name)\n",
    "            # check whether input file matches this scenario\n",
    "            # open input zip file\n",
    "            with zipfile.ZipFile(os.path.join(data_folder, fr'{input_file[:-4]}.zip'), 'r') as zip_ref:\n",
    "                # read input csv\n",
    "                with zip_ref.open(input_file) as input_data_file:\n",
    "                    df_input = pd.read_csv(input_data_file)\n",
    "                    row_matches_scenario = all(df_input.iloc[0][key] == value for key, value in scenario.items())\n",
    "                    \n",
    "            # get data if input values match this scenario\n",
    "            if row_matches_scenario:\n",
    "                with zipfile.ZipFile(os.path.join(data_folder, fr'{file[:-4]}.zip'), 'r') as zip_ref:\n",
    "                    # read data csv\n",
    "                    with zip_ref.open(file) as data_file:\n",
    "                        # try to read collision data (will fail when empty)\n",
    "                        try:\n",
    "                            df_collisions = pd.read_csv(data_file)\n",
    "                        # do not process empty collision dataframes\n",
    "                        except:\n",
    "                            continue\n",
    "                        # do process collision  dataframe if it has data\n",
    "                        df_collisions['run'] = run_number\n",
    "\n",
    "                        # broadcast input data to all rows of collision dataframe\n",
    "                        for col in df_input.columns:\n",
    "                            df_collisions[col] = df_input[col].iloc[0]\n",
    "                    \n",
    "                        # add this data to the main DataFrame\n",
    "                        df = pd.concat([df, df_collisions])\n",
    "    \n",
    "    # return resulting DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeca9d3-6a43-4e11-a088-64498a328002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scenario\n",
    "scenario_a = {\n",
    "    'level0_fraction': 0.25,\n",
    "    'level1_fraction': 0.25,\n",
    "    'level2_fraction': 0.25,\n",
    "    'level3_fraction': 0.25,\n",
    "    'in_vehicle_distraction': True,\n",
    "    'road_side_distraction': False\n",
    "}\n",
    "\n",
    "# define scenario\n",
    "scenario_b = {\n",
    "    'level0_fraction': 0.0,\n",
    "    'level1_fraction': 0.33,\n",
    "    'level2_fraction': 0.33,\n",
    "    'level3_fraction': 0.33,\n",
    "    'in_vehicle_distraction': True,\n",
    "    'road_side_distraction': False\n",
    "}\n",
    "\n",
    "scenario_labels = ['25-25-25-25', '0-33-33-33']\n",
    "scenario_colors = ['steelblue', 'darkorange']\n",
    "\n",
    "# function to filter a dataframe based on the scenario input values\n",
    "def filter_dataframe_on_scenario(df, scenario):\n",
    "    df_filtered = df[\n",
    "        (df['level0_fraction'] == scenario['level0_fraction']) &\n",
    "        (df['level1_fraction'] == scenario['level1_fraction']) &\n",
    "        (df['level2_fraction'] == scenario['level2_fraction']) &\n",
    "        (df['level3_fraction'] == scenario['level3_fraction']) &\n",
    "        (df['in_vehicle_distraction'] == scenario['in_vehicle_distraction']) &\n",
    "        (df['road_side_distraction'] == scenario['road_side_distraction'])\n",
    "    ]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705882a-1b2c-4266-a5d1-65b5c6a4abc3",
   "metadata": {},
   "source": [
    "## Traffic performance\n",
    "\n",
    "### Speed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfbba7f-e91d-4b26-b425-475d676cf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get speed data scenario 1\n",
    "speed_variables = ['time', 'speed', 'x_position', 'lane']\n",
    "df_gtu_speed_a = load_scenario_dataframe(scenario_a, speed_variables, experiment_folder, sequence_output, input_values)\n",
    "# convert speed to km/h\n",
    "df_gtu_speed_a['speed'] = df_gtu_speed_a['speed'] * 3.6\n",
    "\n",
    "# get speed data scenario 2\n",
    "df_gtu_speed_b = load_scenario_dataframe(scenario_b, speed_variables, experiment_folder, sequence_output, input_values)\n",
    "# convert speed to km/h\n",
    "df_gtu_speed_b['speed'] = df_gtu_speed_b['speed'] * 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eec78c-c248-403c-b2e5-795322267de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean speed distribution\n",
    "def show_speed_distribution(data_list, labels, section_positions, section_labels):\n",
    "    # define colors for each DataFrame\n",
    "    colors = ['steelblue', 'darkorange']\n",
    "    \n",
    "    # create figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # width of each individual bar\n",
    "    bar_width = 20\n",
    "    num_dfs = len(data_list)\n",
    "    \n",
    "    # loop through provided DataFrames\n",
    "    for i, df in enumerate(data_list):\n",
    "        # create bins based on x position and calculate the mean speed\n",
    "        df['x_bin'] = (df['x_position'] // 50) * 50\n",
    "        mean_speed_per_bin = df.groupby('x_bin')['speed'].mean().reset_index()\n",
    "\n",
    "        # shift bars horizontally\n",
    "        x_positions = mean_speed_per_bin['x_bin'] + i * bar_width - (num_dfs * bar_width / 2) + 30\n",
    "\n",
    "        # plot each bar\n",
    "        plt.bar(x_positions, mean_speed_per_bin['speed'], width=bar_width, color=colors[i % len(colors)], label=labels[i])\n",
    "\n",
    "    # custom ticks for section boundaries\n",
    "    plt.xticks(section_positions, section_labels)\n",
    "        \n",
    "    # show plot\n",
    "    plt.xlabel('Position (100-meter bins)')\n",
    "    plt.ylabel('Mean Speed (m/s)')\n",
    "    plt.title('Mean Speed per 100-meter Segment')\n",
    "    plt.legend(title='DataFrames')\n",
    "    plt.show()\n",
    "\n",
    "# plot mean speed heatmap\n",
    "def show_speed_heatmap(data_list, labels, section_positions, section_labels):\n",
    "    # segment length\n",
    "    segment_length = 25\n",
    "    \n",
    "    # define colors for each DataFrame\n",
    "    cmap = plt.cm.RdYlGn\n",
    "    norm = plt.Normalize(0, 150)\n",
    "\n",
    "    # create subplots\n",
    "    fig, axes = plt.subplots(len(data_list), 1, figsize=(12, 1.2 * len(data_list)), sharex=True)\n",
    "\n",
    "    # also enable axes[i] if only one dataframe is provided\n",
    "    if len(data_list) < 2:\n",
    "        axes = [axes]\n",
    "\n",
    "    # loop through provided DataFrames\n",
    "    for i, df in enumerate(data_list):\n",
    "        # grey background color to represent the road\n",
    "        axes[i].set_facecolor(\"lightgrey\")\n",
    "        \n",
    "        # create bins based on x position and calculate the mean speed\n",
    "        df['x_bin'] = (df['x_position'] // segment_length) * segment_length\n",
    "        mean_speed_per_bin = df.groupby('x_bin')['speed'].mean().reset_index()\n",
    "\n",
    "        # Plot each segment as a colored rectangle with color representing speed\n",
    "        for _, row in mean_speed_per_bin.iterrows():\n",
    "            x_start = row['x_bin']\n",
    "            x_end = x_start + segment_length\n",
    "            speed = row['speed']\n",
    "            color = cmap(norm(speed))  # Get color based on speed\n",
    "            \n",
    "            # Plot the filled rectangle for the segment\n",
    "            axes[i].fill_between([x_start, x_end], 0, 1, color=color)\n",
    "        \n",
    "        # Set labels and title for each subplot\n",
    "        axes[i].set_ylabel(labels[i], rotation=0, labelpad=50, fontsize=12)\n",
    "        axes[i].set_yticks([])  # Hide y-axis ticks to give it a \"road\" appearance\n",
    "        axes[i].set_ylim(0, 1)\n",
    "    \n",
    "    # Set section labels and positions on the shared x-axis\n",
    "    plt.xticks(section_positions, section_labels, fontsize=12)\n",
    "    plt.xlabel('Freeway longitudinal positions', fontsize=12)\n",
    "    plt.suptitle('Mean speed heatmap along freeway main lanes', fontsize=14)\n",
    "    \n",
    "    # Add a colorbar for speed\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=axes, orientation='vertical', label='Mean speed (km/h)', aspect=10, pad=0.01)\n",
    "    cbar.set_label('Mean speed (km/h)', fontsize=11)\n",
    "    cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01257133-7eca-43e0-8444-38404a3fc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe on road section, do not include on-ramp lanes\n",
    "main_lanes = ['LEFT', 'RIGHT']\n",
    "df_gtu_speed_a_main = df_gtu_speed_a[df_gtu_speed_a['lane'].isin(main_lanes)].copy()\n",
    "df_gtu_speed_b_main = df_gtu_speed_b[df_gtu_speed_b['lane'].isin(main_lanes)].copy()\n",
    "\n",
    "# show speed bar plot\n",
    "section_pos = [0, 825, 1175, 2000]\n",
    "sections = ['A', 'B', 'C', 'D']\n",
    "show_speed_distribution([df_gtu_speed_a_main, df_gtu_speed_b_main], scenario_labels, section_pos, sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a41db-9604-4bf1-9137-7095bf51bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_speed_heatmap([df_gtu_speed_a_main, df_gtu_speed_b_main], scenario_labels, section_pos, sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64308478-6c33-4940-8e2e-95d0be4853fe",
   "metadata": {},
   "source": [
    "### Travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fe1d8-57bd-46f9-8b0e-7b0f11b4e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show travel time boxplots\n",
    "def plot_travel_times(data_list, labels, colors):\n",
    "    # Define travel time columns to plot\n",
    "    travel_time_columns = ['travel_time', 'main_travel_time', 'ramp_travel_time']\n",
    "    \n",
    "    # Create figure and subplots for each travel time column\n",
    "    fig, axes = plt.subplots(1, len(travel_time_columns), figsize=(12, 6), sharey=True)\n",
    "    fig.suptitle('Travel time comparison', fontsize=14)\n",
    "    \n",
    "    # Loop over each travel time column to create a subplot\n",
    "    for i, col in enumerate(travel_time_columns):\n",
    "        # Collect data for the current travel time column from each DataFrame\n",
    "        data_to_plot = [df[col].dropna() for df in data_list]  # Drop NaNs for cleaner boxplots\n",
    "        \n",
    "        # Plot the boxplot in the respective subplot\n",
    "        box = axes[i].boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
    "        axes[i].set_xlabel(col.capitalize().replace('_', ' '), fontsize=12)\n",
    "        axes[i].set_ylim(bottom=0)\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('Travel time (s)', fontsize=12)  # Set y-axis label only once for clarity\n",
    "\n",
    "        for patch, color in zip(box['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "    \n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b9271-1cfe-4ed8-b2ac-ad1e3eef3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get speed data scenario 1\n",
    "travel_time_variables = ['travel_time', 'main_travel_time', 'ramp_travel_time']\n",
    "df_gtu_speed_a = load_scenario_dataframe(scenario_a, travel_time_variables, experiment_folder, intermediate_output, input_values)\n",
    "\n",
    "# get speed data scenario 2\n",
    "df_gtu_speed_b = load_scenario_dataframe(scenario_b, travel_time_variables, experiment_folder, intermediate_output, input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051889f-f19c-4f77-8cd1-566289d94d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show travel time data\n",
    "plot_travel_times([df_gtu_speed_a, df_gtu_speed_b], labels=scenario_labels, colors=scenario_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7dcdab-2b65-422e-abc7-b91356aad3fc",
   "metadata": {},
   "source": [
    "### Fundamental diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34e649-72a6-4e25-881e-c5c6b762fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time column\n",
    "def add_time_column(df, sample_interval):\n",
    "    df['time'] = df.groupby(['seed', 'run']).cumcount() * sample_interval\n",
    "    return df\n",
    "\n",
    "# filter columns\n",
    "def filter_columns(df, selected_variables):\n",
    "    columns_to_include = [col for col in df.columns if col in selected_variables]\n",
    "    df = df[columns_to_include]\n",
    "    return df\n",
    "\n",
    "# convert data\n",
    "def convert_fd_data(df):\n",
    "    df_converted = df.copy()\n",
    "    for col in df_converted.columns.tolist():\n",
    "        if 'flow' in col:\n",
    "            df_converted[col] = df_converted[col].astype(float) * 3600\n",
    "        if 'density' in col:\n",
    "            df_converted[col] = df_converted[col].astype(float) * 1000\n",
    "        if 'speed' in col:\n",
    "            df_converted[col] = df_converted[col].astype(float) * 3.6\n",
    "    return df_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62eefc-eb91-44e4-afa3-2d9d1eec598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select merging lanes and required FD variables\n",
    "variables = ['AB.LEFT_density', 'AB.LEFT_flow', 'AB.LEFT_speed',\n",
    "             'AB.RIGHT_density', 'AB.RIGHT_flow', 'AB.RIGHT_speed',\n",
    "             'BC.LEFT_density', 'BC.LEFT_flow', 'BC.LEFT_speed',\n",
    "             'BC.RIGHT_density', 'BC.RIGHT_flow', 'BC.RIGHT_speed',\n",
    "             'BC.ONRAMP_density', 'BC.ONRAMP_flow', 'BC.ONRAMP_speed',\n",
    "             'CD.LEFT_density', 'CD.LEFT_flow', 'CD.LEFT_speed',\n",
    "             'CD.RIGHT_density', 'CD.RIGHT_flow', 'CD.RIGHT_speed',\n",
    "             'E2B.ONRAMP_density', 'E2B.ONRAMP_flow', 'E2B.ONRAMP_speed'\n",
    "            ]\n",
    "# scenario 0\n",
    "# get intermediate FD data\n",
    "df_fd_a = load_scenario_dataframe(scenario_a, variables, experiment_folder, intermediate_output, input_values)\n",
    "# remove empty rows (these exist because other variables are also stored in the intermediate CSV)\n",
    "# flow variable is always 0, so NaN value indicates that no data was recorded at all\n",
    "df_fd_a = df_fd_a.dropna(subset=['BC.RIGHT_flow'])\n",
    "# add time column, each FD calculation represents 30 sec\n",
    "df_fd_a = add_time_column(df_fd_a, 30)\n",
    "# select columns of interest\n",
    "variables_of_interest = ['time', 'seed', 'run', 'main_demand', 'ramp_demand'] + variables\n",
    "df_fd_a = filter_columns(df_fd_a, variables_of_interest)\n",
    "\n",
    "# scenario 1\n",
    "# get intermediate FD data\n",
    "df_fd_b = load_scenario_dataframe(scenario_b, variables, experiment_folder, intermediate_output, input_values)\n",
    "# remove empty rows (these exist because other variables are also stored in the intermediate CSV)\n",
    "# flow variable is always 0, so NaN value indicates that no data was recorded at all\n",
    "df_fd_b = df_fd_b.dropna(subset=['BC.RIGHT_flow'])\n",
    "# add time column, each FD calculation represents 30 sec\n",
    "df_fd_b = add_time_column(df_fd_b, 30)\n",
    "# select columns of interest\n",
    "variables_of_interest = ['time', 'seed', 'run', 'main_demand', 'ramp_demand'] + variables\n",
    "df_fd_b = filter_columns(df_fd_b, variables_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16250bc0-01aa-4f39-ab45-411c57346662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine road areas\n",
    "def create_freeway_sections(df):\n",
    "    df_combined = pd.DataFrame()\n",
    "    # get run info\n",
    "    df_combined['time'] = df['time']\n",
    "    df_combined['main_demand'] = df['main_demand']\n",
    "    df_combined['ramp_demand'] = df['ramp_demand']\n",
    "    df_combined['seed'] = df['seed']\n",
    "    df_combined['run'] = df['run']\n",
    "    # create AB section (main lanes pre-merging)\n",
    "    df_combined['AB_flow'] = df['AB.LEFT_flow'] + df['AB.RIGHT_flow']\n",
    "    df_combined['AB_density'] = (df['AB.LEFT_density'] + df['AB.RIGHT_density']) / 2\n",
    "    df_combined['AB_speed'] = (df['AB.LEFT_speed'] + df['AB.RIGHT_speed']) / 2\n",
    "    # create BC section (main lanes + merging lane)\n",
    "    df_combined['BC_flow'] = df['BC.LEFT_flow'] + df['BC.RIGHT_flow'] + df['BC.ONRAMP_flow']\n",
    "    df_combined['BC_density'] = (df['BC.LEFT_density'] + df['BC.RIGHT_density'] + df['BC.ONRAMP_density']) / 3\n",
    "    df_combined['BC_speed'] = (df['BC.LEFT_speed'] + df['BC.RIGHT_speed'] + df['BC.ONRAMP_speed']) / 3\n",
    "    # create CD section (main lanes post-merging)\n",
    "    df_combined['CD_flow'] = df['CD.LEFT_flow'] + df['CD.RIGHT_flow']\n",
    "    df_combined['CD_density'] = (df['CD.LEFT_density'] + df['CD.RIGHT_density']) / 2\n",
    "    df_combined['CD_speed'] = (df['CD.LEFT_speed'] + df['CD.RIGHT_speed']) / 2\n",
    "    # also include onramp lane\n",
    "    df_combined['E2B.ONRAMP_flow'] = df['E2B.ONRAMP_flow']\n",
    "    df_combined['E2B.ONRAMP_density'] = df['E2B.ONRAMP_density']\n",
    "    df_combined['E2B.ONRAMP_speed'] = df['E2B.ONRAMP_speed']\n",
    "\n",
    "    # return DataFrame with combined lanes as road sections\n",
    "    return df_combined\n",
    "\n",
    "# create freeway sections and convert units\n",
    "df_fd_combined_a = create_freeway_sections(df_fd_a)\n",
    "df_new_fd_a = convert_fd_data(df_fd_combined_a)\n",
    "\n",
    "df_fd_combined_b = create_freeway_sections(df_fd_b)\n",
    "df_new_fd_b = convert_fd_data(df_fd_combined_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4043d5c-23b9-4efc-bd32-112f05c9e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fd_max_flow(data_list, labels, sections, colors):\n",
    "    # set bin width\n",
    "    bin_width = 2\n",
    "    \n",
    "    # show plot for each section\n",
    "    for section in sections:\n",
    "    \n",
    "        # create figure\n",
    "        plt.figure(figsize=(8, 6))\n",
    "    \n",
    "        # define columns\n",
    "        density_col = f'{section}_density'\n",
    "        flow_col = f'{section}_flow'\n",
    "    \n",
    "        # loop through dataframes\n",
    "        for i, df in enumerate(data_list):\n",
    "            # calculate max flow for each density bin\n",
    "            df['density_bin'] = (df[density_col] // bin_width) * bin_width\n",
    "            max_flow_per_bin = df.groupby('density_bin')[flow_col].max().reset_index()\n",
    "\n",
    "            # plot max flow points and fill area under the curve\n",
    "            plt.plot(max_flow_per_bin['density_bin'], max_flow_per_bin[flow_col], label=labels[i], color=colors[i])\n",
    "            plt.fill_between(max_flow_per_bin['density_bin'], max_flow_per_bin[flow_col], color=colors[i], alpha=0.3)\n",
    "\n",
    "    # show plot\n",
    "    # plt.title(f'Fundamental Diagram for section {section}: Max flow per density interval')\n",
    "    plt.title(f'Freeway section {section}')\n",
    "    plt.xlabel('Density (veh/km)', fontsize=11)\n",
    "    plt.ylabel('Max flow (veh/h)', fontsize=11)\n",
    "    plt.xlim(left=0, right=100)\n",
    "    plt.ylim(bottom=0, top=5000)\n",
    "    plt.xticks(np.arange(0, 105, 5))\n",
    "    plt.yticks(np.arange(0, 6000, 500))\n",
    "    plt.legend(title='Scenario')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc777f-082f-484a-8213-520391ac28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fd_max_flow([df_new_fd_a, df_new_fd_b], scenario_labels, ['AB'], scenario_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda131dc-bc4f-4a31-97a3-4a1ad034cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fd_max_flow([df_new_fd_a, df_new_fd_b], scenario_labels, ['BC'], scenario_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909ef91-aa18-48cb-8985-2ea20a293509",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fd_max_flow([df_new_fd_a, df_new_fd_b], scenario_labels, ['CD'], scenario_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313edba-93d8-4985-afee-3aaf91596a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fd_max_flow([df_new_fd_a, df_new_fd_b], scenario_labels, ['E2B.ONRAMP'], scenario_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f78344-013e-4497-b750-dc5eb2f1c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2466a39-7a47-4628-8c2e-a0c7f71fa624",
   "metadata": {},
   "source": [
    "### TTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046736e-3085-4240-b4f4-33393b45c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter collided GTUs from ttc DataFrame\n",
    "def remove_collisions(df, df_collisions):\n",
    "    # loop through collisions DataFrame\n",
    "    for _, row in df_collisions.iterrows():\n",
    "        # get list of GTUs involved in this collision\n",
    "        gtu_ids_to_remove = [row['gtu_id'], row['leader_gtu_id']]\n",
    "        seed = row['seed']\n",
    "        run = row['run']\n",
    "        \n",
    "        # filter out collided GTUs\n",
    "        df = df[~(\n",
    "            (df['gtu_id'].isin(gtu_ids_to_remove)) &\n",
    "            (df['seed'] == seed) &\n",
    "            (df['run'] == run)\n",
    "        )]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f4921-7f26-44aa-a1c9-9b2e3293f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collisions_a = load_scenario_collision_dataframe(scenario_a, experiment_folder)\n",
    "df_collisions_b = load_scenario_collision_dataframe(scenario_b, experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa278c7-da7f-4f61-9bbe-850891c27ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get TTC data\n",
    "ttc_variables = ['time', 'gtu_id', 'gtu_type', 'ttc', 'reaction_time']\n",
    "df_ttc_a = load_scenario_dataframe(scenario_a, ttc_variables, experiment_folder, sequence_output, input_values)\n",
    "df_ttc_b = load_scenario_dataframe(scenario_b, ttc_variables, experiment_folder, sequence_output, input_values)\n",
    "\n",
    "# not all data samples have a TTC, so filter for NaN\n",
    "df_ttc_a = df_ttc_a.dropna(subset=['ttc'])\n",
    "df_ttc_b = df_ttc_b.dropna(subset=['ttc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444a345-ed18-4db5-a0c5-3cbc0c294464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove collisions from TTC data\n",
    "df_ttc_a = remove_collisions(df_ttc_a, df_collisions_a)\n",
    "df_ttc_b = remove_collisions(df_ttc_b, df_collisions_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649ccd9-a39a-4194-9a6c-f48c17df52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine critical TTCs per automation level\n",
    "def calculate_critical_ttc(df):\n",
    "    # create masks that determine whether a TTC is critical\n",
    "    level0_critical_mask = (df['gtu_type'] == 'LEVEL0') & (df['ttc'] < df['reaction_time'])\n",
    "    other_levels_ciritcal_mask = (df['gtu_type'] != 'LEVEL0') & (df['ttc'] < 0.5)\n",
    "\n",
    "    # find ciritcal TTCs by masks\n",
    "    df['ttc_is_critical'] = level0_critical_mask | other_levels_ciritcal_mask\n",
    "\n",
    "    # group per GTU level\n",
    "    df_critical_ttc_counts = df[df['ttc_is_critical']].groupby('gtu_type')['ttc_is_critical'].sum().reset_index()\n",
    "    df_critical_ttc_counts = df_critical_ttc_counts.rename(columns={'ttc_is_critical': 'critical_ttc_count'})\n",
    "\n",
    "    # ensure all gtu_types are represented\n",
    "    gtu_types = sorted(df['gtu_type'].unique())\n",
    "    for gtu_type in gtu_types:\n",
    "        if gtu_type not in df_critical_ttc_counts['gtu_type'].tolist():\n",
    "            df_critical_ttc_counts = pd.concat([df_critical_ttc_counts, pd.DataFrame({'gtu_type': [gtu_type], 'critical_ttc_count': [0]})])\n",
    "\n",
    "    # return cirtical TTC count\n",
    "    return df_critical_ttc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cbc18-ca52-4bb0-b10d-4b0e4bbef462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critical_ttc_a = calculate_critical_ttc(df_ttc_a)\n",
    "df_critical_ttc_b = calculate_critical_ttc(df_ttc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b302f-27f9-4a55-a330-ccd7ad83d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_critical_ttc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9f956-eb75-4d64-b70d-b3cebb3bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_critical_ttc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef89015-86ee-4cc5-8982-8cf208e41a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show bar plot for critical TTC\n",
    "def show_critical_ttc_plot(data_list, labels, colors):\n",
    "    df1 = data_list[0]\n",
    "    df2 = data_list[1]\n",
    "\n",
    "    all_gtu_types = sorted(df2['gtu_type'].unique())\n",
    "    df1 = df1.set_index('gtu_type').reindex(all_gtu_types, fill_value=0).reset_index()\n",
    "    df2 = df2.set_index('gtu_type').reindex(all_gtu_types, fill_value=0).reset_index()\n",
    "\n",
    "    x = np.arange(len(all_gtu_types))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.bar(x - width/2, df1['critical_ttc_count'], width, label=labels[0], color=colors[0])\n",
    "    ax.bar(x + width/2, df2['critical_ttc_count'], width, label=labels[1], color=colors[1])\n",
    "\n",
    "    ax.set_xlabel('Automation level', fontsize=11)\n",
    "    ax.set_ylabel('Number of critical TTCs', fontsize=11)\n",
    "    ax.set_title('Comparison of critical TTCs per automation level', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(all_gtu_types)\n",
    "    ax.legend(title='Scenario')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed38ff9-77f8-48a3-913f-37977063f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_critical_ttc_plot([df_critical_ttc_a, df_critical_ttc_b], scenario_labels, scenario_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb78c10-4dc7-4472-b66e-f37e01d22979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
